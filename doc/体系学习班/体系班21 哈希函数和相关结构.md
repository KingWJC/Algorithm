# 哈希函数

定义：**out f(int data)**

## **性质：**

1. 输入参数类型in，特征：可能性无穷大；比如String类型的参数

2. 输出参数类型out，特征：可能性有穷尽，相对有限，可以很大；如Int32类型 $1\dots2^{64}-1$。

3. 相同的输入一定有相同的输出。（没有随机机制）

4. 哈希碰撞：不同的输入可能有相同的输出。（因为输入无穷多，但输出值有限）

5. 大量不同的输入值，得到的输出值会几乎**均匀的分布**在out域上。

   比如：1万个不同的值映射在（$1\dots2^{64}-1$）的范围轴上，用长度固定的范围在不同的位置上截取，得到的映射点的个数几乎一样。也就是说映射点在out域上**离散分布**（即使是微小的差异也会放大）。

   房间内打碎香水瓶，房间任意空间都有香水味。

   **重点：具有离散性和均匀分布性**。相当于哈希函数需要和输入的数据状况解耦，所以离散性和一个范围内的均匀性是一回事。

**作用**：可以把数据根据不同值，几乎均匀的分开。

**哈希值的计算**：就是将字符串的二进制表示用一系列计算打乱，得到HashCode。

**均匀分布的传递性**

大量不同的字符串通过哈希函数得到的16进制的HashCode（如C1,C2,C3...），在（$1\dots2^{128}-1$）范围轴上均匀分布，若将HashCode都模10，如Cx=Cx%10，则得到的结果都在0~9的范围上，**且也是均匀分布的**。

## 哈希表的设计

1. 建一个17长度的数组，数组中每个位置是一个链表。

2. 每个字符串通过哈希函数计算出的哈希值，再模上17，挂在数组中链表上。

   **因为哈希函数有均匀性，数组中0~16上的链表均匀增长**。

3. 查找和删除，都是先计算hashCode%17，找到数据所在的链表，然后遍历。

如果加入N条记录，则每个链表的长度是17/N，因为遍历的代价，时间复杂度是O(N)

但哈希表的时间复杂度是O(1)的原因是：扩容操作。

1. 人为规定：链表长度为6时，进行扩容。
2. 数组长度增加1倍，每条数据重新计算hashCode%34，重新挂在34长度的数组上，最终每个链表的长度都减半。

时间复杂度O(1)的验证：

1. **假设最差情况**：数组长度为1，链表长度为2时，就进行扩容。已加入1000条数据。

2. 经历了logN次扩容。因为只有超过2的倍数才扩容。

3. 长度为2时，扩容操作为2，数组长度为2
   长度为3时，扩容操作为3，数组长度为4
   长度为5时，扩容操作为5，数组长度为8
   长度为9时，扩容操作为9，数组长度为16......
   近似一个等比数列，求和公式S=2^N-1。总的时间复杂度O(N)，单次代价O(1)

4. 工程上的改进：

   链表使用红黑树，比链表放入的值多。

   时间复杂度不变，是它的常数项变小。

# 布隆过虑器

服务：url黑名单，插入100亿条url，如果url在黑名单中，就拒绝访问。

1. 使用HashSet实现，会造成空间浪费：因为HashSet存储字符串，每条记录占64字节，100亿条记录需要6400亿字节，则内存支持服务运行需要640GB。

2. 使用布隆过虑器，**有失误率**（若是黑名单里的，则100%准确，若不是黑名单里的，则可能会误报。**宁可误杀三千，不会放过一个**），只需要18GB，对空间优化很大，所以工程上应用很广。

   是失误率和空间使用率之间妥协的产物。

位图：

1. int[] 长度为10时，占用空间是40个字节。
2. bit[] 长度为N时，占用N/8个字节。因为byte=8bit。
3. 实现：声明一个int[10]的数组arr，bit[0]代表arr[0]的第一位，bit[31]代表arr[0]的第31位，bit[32]代表arr[1]的第一位。所以实际上是声明了一个长度为320的bit[]数组。

**布隆过虑器是一系列逻辑加位图的整体。**

实现步骤：

1. 准备一个m长度的bit数组arr，占用$m\over8$个byte。以及3个独立的哈希函数$f_1,f_2,f_3$。
2. 每个url进入黑名单时，url字符串使用3个哈希函数得到3个HashCode，都%m，则在arr数组上的3个位置设为1。arr[C1%m]=1,arr[C2%m]=1,arr[C3%m]=1。（3个HashCode有几率一样）
3. 查询url是否在黑名单中，先用3个哈希函数计算HashCode%m，在arr上取出3个位置的结果状态，如果有一个为0，说明url在之前没加入过。如果都为1，则说明url在之前加入过。（哈希函数：相同的输入一定有相同的输出）

问题的关键：假如n=100亿，p=0.0001

1. m定多大？

   m过小，则失误率太大；m过大，则空间浪费。

   m越大，失误率越小，但失误率不可避免。

   相关因素：（1.样本量n；2.失误率p；3.单样本大小）

   只和1，2有关，和3无关（任何样本只要能算出HashCode就行，和大小无关）。

   <img src="images/Screen%20Shot%202022-02-20%20at%208.37.10%20PM.png" alt="Screen Shot 2022-02-20 at 8.37.10 PM" style="zoom:50%;" />

   公式得：m=143亿bit，是17亿个字节byte，就是16.68GB。是理论上至少的空间m。

   和面试官争取，如果空间给20GB，可以让失误率降低。则有了实际拿到的空间m"。

2. 哈希函数k定多少个？

   如果k越小，采样不足，失误率变大。

   如果k越小，采样太多，空间m很快被耗尽，失误率变大。

   <img src="images/Screen%20Shot%202022-02-20%20at%208.52.47%20PM.png" alt="Screen Shot 2022-02-20 at 8.52.47 PM" style="zoom:50%;" />

   公式得：$k=0.7\times\frac{m^"}{n}=1.5$，使用m得1.27，向上取整为k"=2.

3. 通过公式重新计算真实的P，一定比0.0001万分之一小。

流程：

1. 利用哈希函数的性质   

2. 每一条数据提取特征   

3. 加入描黑库   

布隆过滤器的失误率：

- 说一个数存在有可能错误的，判断它不在肯定是对的   
- 把本来不存在布隆过滤器中的元素误判为存在的情况,我们把它叫做假阳性(False Positive) 
- [False Positive & False Negative假阴性]

## 公式

假设数据量为n，预期的失误率为p（布隆过滤器大小和每个样本的大小无关）

1. 根据n和p，算出Bloom Filter一共需要多少位bit，因为长度是整数，所以向上取整，记为m。
   $$
   \large m=-\frac{n\times \ln p}{(\ln2)^2}
   $$

2. 根据m和n，算出Bloom Filter一共需要多少个哈希函数，向上取整，记为k。
   $$
   k=\ln2\times\frac{m}{n}=0.7\times\frac{m}{n}
   $$

3. 根据实际的m"和真实的k"，算出真实的失误率p"
   $$
   p=\left(1-e^{-\frac{n k}{m}}\right)^k
   $$

面试时两问：题目是真实样本量n=100亿，样本大小64byte。

1. 系统是否允许有失误率？有的话，一定是用布隆过虑器实现
2. 预期的失误率是多小？千分之一，或万分之一。可得到m
3. m是否可以调大？ 得m"，可算出k，向上取整得k"真。
4. 再算出P"真。一定比预期的失误率低。

多个哈希函数如何搞：

1. 先建立两个哈希函数$f_1,f_2$
2. 第一个哈希函数就是：$f_1=1\times f_1+f_2$
3. 第一个哈希函数就是：$f_2=2\times f_1+f_2$
4. 第一个哈希函数就是：$f_3=3\times f_1+f_2$
5. 造k个，几乎独立。最终都要%m。

在Hadoop分布式文件系统(*HDFS*)中的妙用：

- 分块存储记录，如A，B，C三个块。
- 每个块维护一个小的布隆过虑器。
- 若想知道记录abc在哪个块中，只需遍历布隆过虑器，在中有的块中查找。而不需要遍历所有块。
- 和HyperLogLog不同，其设计原则是，林子大了什么鸟去都有，所以可以根据鸟有多少类，来评估林子有多大。

其它：布谷鸟过虑器。

# 一致性哈希

## 经典的服务器存储结构

### 步骤

1. 一个网络请求Request，想存储Name="wjc"的age=33的数据。

2. 前端有多台机器，绑定同一个域名。所有机器没有差别，也没有专属数据。

   请求通过域名，分配到前端的某台机器上。

3. 然后到逻辑端，有多台服务器。（绝大多数的程序开发在此处部属服务），所有机器没有专属数据，也是无差别的。在逻辑端的某台机器上，处理业务。

4. 最后到数据端，如Oracle，mysql。假如数据端有3台服务器，A0，B1，C2。

   如何确定数据要存储在哪台服务器上？经典的数据存储方法是：计算"wjc"的HashCode，再%3，如果结果是0，则Name="wjc"的age为33的数据放入A机器。

   可以实现负载均衡，因为哈希函数的离散性和均匀分布性。3台机器存储的数据量差不多。

### 合适的Hashkey

哪个字段是用它的哈希值来确定数据分片的，在业务上上它叫**Hashkey**。

苦选择不当的Hashkey，比如选择国家作为key，但在业务上，只有中国和美国的数据多，日本的数据很少。这就意味着key虽然均分，但总有一台服务器的数据没有其它两台多。、

业务上有高频，也会导致负载不均衡。

所以选择合适的key的方式是：

1. 高、中、低频的key，都应该有一定的量。3种key都会均分在服务器上。
2. 只能从业务上挖掘，什么字段适合做Hashkey。

### 问题

虽然3台机器的数据分布非常均衡，但如果后期增加或减少机器，则**数据迁移量是全量**。因为之前模过的数据都失效了，需要全部重新计算。

## 分布式存储结构

一致性哈希解决数据存储的问题，使数据迁移不是全量，可以极大减少，且保证负载均衡。

### 哈希域变成环的设计

哈希域：哈希函数的返回值

示例：3台机器m1（ip1），m2（ip2），m3（ip3），哈希域是$0\dots2^{64}-1$的环。

使用ip做key，计算hashCode，将m1,m2,m3映射到环上。（机器在环止有冲突的可能性，但样本量小的情况下可以不考虑。即使冲突，就让m1,m2保存同样的数据，不是事故。）

当有数据Name="wjc"，age=33需要存储时，计算HashCode映射在环上，存储在顺时针遇到的第一台机器上。

如果加新机器m4，只需将顺时针遇到的第一台机器m1上的数据拿走一部分。若是移除，就将数据迁移到顺时针遇到的第一台机器m1上。

<img src="images/Screen%20Shot%202022-02-21%20at%203.38.25%20PM.png" alt="Screen Shot 2022-02-21 at 3.38.25 PM" style="zoom: 50%;" />

顺时针查找遇到的第一台机器的方法：

1. 3台机器m1,m2,m3计算HashCode值，放入数组中并进行排序，[7，9，63]。

2. 逻辑端中，每台机器都保留这个有序数组（路由）。

3. 如果数据计算的HashCode是56，则在有序数组中找到大于56的值所对应的机器，若没有，则取第一个。

   查找过程可以二分。

问题：

1. 如何保证3台机器把环均分？少量机器会造成Hashkey分布不均。
2. 即使人为分配固定的HashKey，可以均分环，但如果加机器，则又无法均分。

### 虚拟节点技术

解决物理机映射在环上，或增删机器后，分配不均的问题。

方法：

1. 生成虚拟节点路由表，可以很容易查到哪个字符串属于哪台机器。
   给m1, 分配1000个字符串（虚拟节点）【a1......a1000】
   给m2, 分配1000个字符串【b1......b1000】
   给m3, 分配1000个字符串【c1.......c1000】

2. 虚拟节点映射到环上。m1,m2,m3可以实现均匀分布。**实现负载均衡**。

3. 若增加机器m4，则给m4, 分配1000个字符串（虚拟节点）【d1.......d1000】

   虚拟节点上环以后，m4会向m1,m2,m3要来几乎等量$\frac{1}{12}$的数据，组成自己的$\frac{1}{4}$段。

   迁移代价是$\frac14$的数据量。

   根据哈希函数的均匀分布性，则m1,m2,m3原始是$\frac13$，每台机器减去x的数据量，则$3x=\frac14,x=\frac{1}{12}$。

4. 可以**实现负载管理**，如果m1机器性能高，则分配2000个虚拟节点；m2,m3机器性能一般，则分配1000个虚拟节点，m4机器性能差，则分配500个虚拟节点，



**一致性哈希里没有模。**

